{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c690a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Labels ===\n",
      "asp_clarity                 A-clarity\n",
      "asp_meaningful-comparison   B-meaningful-comparison\n",
      "asp_motivation-impact       C-motivation-impact\n",
      "asp_originality             D-originality\n",
      "asp_replicability           E-replicability\n",
      "asp_soundness-correctness   F-soundness-correctness\n",
      "asp_substance               G-substance\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "import disapere_lib\n",
    "\n",
    "openai.api_key_path = \"nnk_openai_api_key.txt\"\n",
    "\n",
    "\n",
    "dataset = disapere_lib.get_dataset('aspect')\n",
    "label_map = {y: f'{x}-{y[4:]}' for x, y in zip(\"ABCDEFG\", sorted(dataset['train'].keys())[1:-1])}\n",
    "\n",
    "old_label_list = sorted(label_map.keys())\n",
    "\n",
    "print(\"=== Labels ===\")\n",
    "for k, v in label_map.items():\n",
    "  print(k.ljust(28) + f'{v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7337e50b",
   "metadata": {},
   "source": [
    "# Few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8a2ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 7\n",
      "Number of examples per class in prompt: 3\n",
      "Prompt length: 3382\n",
      "\n",
      "Prompt prefix:\n",
      "========================================================================================================================\n",
      "Sentence: Reward prediction along --> Reward prediction alone\n",
      "Label: A-clarity\n",
      "###\n",
      "Sentence: this limitation in latenby?\n",
      "Label: A-clarity\n",
      "###\n",
      "Sentence: In general, the paper is well written and easy to follow. And the experimental evaluation is extensive and compares with relevant state-of-the-art m...\n",
      "========================================================================================================================\n",
      "\n",
      "Number of examples to label: 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_examples_in_prompt = 3\n",
    "num_examples_to_label = 200\n",
    "\n",
    "\n",
    "prompt = \"\"\n",
    "\n",
    "for old_label, new_label in label_map.items():\n",
    "  for _, text in dataset['train'][old_label][:num_examples_in_prompt]:\n",
    "    prompt += f'Sentence: {text}\\nLabel: {new_label}\\n###\\n'\n",
    "    \n",
    "print(\"Number of classes:\", len(label_map))\n",
    "print(\"Number of examples per class in prompt:\", num_examples_in_prompt)\n",
    "print(\"Prompt length:\", len(prompt))\n",
    "print()\n",
    "\n",
    "print(\"Prompt prefix:\")\n",
    "print(\"=\" * 120)\n",
    "print(prompt[:300]+\"...\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nNumber of examples to label:\", num_examples_to_label)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71dee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 200/200 [03:28<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Weird way of picking examples but whatever\n",
    "for i in tqdm.tqdm(range(num_examples_in_prompt, num_examples_in_prompt + num_examples_to_label)):\n",
    "  label = random.choice(old_label_list)\n",
    "  if i >= len(dataset['train'][label]):\n",
    "    continue\n",
    "    \n",
    "  _, sentence = dataset['train'][label][i]\n",
    "  text = f'{prompt}Sentence: {sentence}\\nLabel: '\n",
    "  \n",
    "  response = openai.Completion.create(\n",
    "    engine = \"text-davinci-003\",\n",
    "    prompt = text,\n",
    "    temperature = 0.6,\n",
    "    max_tokens = 150,\n",
    "  )\n",
    "  \n",
    "  results.append((sentence, label_map[label], response['choices'][0].text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e3e9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid answers: 34%\n",
      "Accuracy: 19%\n"
     ]
    }
   ],
   "source": [
    "valid_answers = 0\n",
    "correct_answers = 0\n",
    "\n",
    "for a, b, c in results:\n",
    "  if c in label_map.values():\n",
    "    valid_answers += 1\n",
    "    if b == c:\n",
    "      correct_answers += 1\n",
    "      \n",
    "valid_percent = valid_answers/len(results)\n",
    "accuracy = correct_answers/len(results)\n",
    "      \n",
    "print(f\"Valid answers: {valid_percent:.0%}\\nAccuracy: {accuracy:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9be880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                     Predicted                     Sentence\n",
      "\n",
      "D-originality             D-originality             ||| Simply because for continuous variables similar experiments have been reported before\n",
      "\n",
      "G-substance               H-presentation-clarity    ||| And the experimental evaluations of this part are convincing and compare favourably with other state-of-the-art methods.\n",
      "\n",
      "F-soundness-correctness   E-replicability           ||| (6) If the authors jointly and simultaneously optimize \\theta and \\phi, why a regularization term about q_{\\phi}(z)  is missing in Eq 12 while a regularization term about \\pi_{\\theta|z} does appear in Eq 12?\n",
      "\n",
      "A-clarity                 A-clarity                 ||| Overall, the paper is well organized and logically clear.\n",
      "\n",
      "A-clarity                 H-presentation            ||| The images are well-presented and well-explained by the captions and the text.\n",
      "\n",
      "F-soundness-correctness   H-clarity-presentation    ||| The derivation of the algorithm in Sec 3.2 is logically clear and easy to follow.\n",
      "\n",
      "G-substance               B-meaningful-comparison   ||| The selected baselines are not sufficient.\n",
      "\n",
      "B-meaningful-comparison   B-meaningful-comparison   ||| I don't think this is really a fair comparison; I would have liked to have seen results for the unmodified reward function.\n",
      "\n",
      "E-replicability           E-replicability           ||| - in section 2.2, please explain more how gradients w.r.t hyper-parameters are computed.\n",
      "\n",
      "A-clarity                 A-clarity                 ||| The paper is well-written, has good experiments, and has a comprehensive related work section.\n",
      "\n",
      "D-originality             D-originality             ||| * Original idea of using separate \"discriminator\" paths for unknown classes\n",
      "\n",
      "B-meaningful-comparison   H-qualitative-analysis    ||| That said, the claims should be weakened to reflect this gap, and domain knowledge should be mentioned more prominently (e.g. states of interest vs context are given, not learned).\n",
      "\n",
      "D-originality             H-overall-assessment      ||| Overall, this paper is good, but is not novel or important enough for acceptance.\n",
      "\n",
      "D-originality             H-overall-evaluation      ||| I am reluctant to give a higher score due to its incremental contribution.\n",
      "\n",
      "B-meaningful-comparison   H-related-work            ||| Some works actually also incorporate generative and/or discriminative networks into MAP inference process for these tasks.\n",
      "\n",
      "D-originality             G-substance               ||| From this viewpoint, the actor-critic component in Dreamer is an incremental contribution.\n",
      "\n",
      "A-clarity                 H-generality              ||| The approach is evaluated only in three cases: fish, walker, cheetah. Can it be applied to more complex morphologies? Humanoid etc. maybe?\n",
      "\n",
      "A-clarity                 A-clarity                 ||| => The results shown in Figure-4 (Section-4.2) seems unclear to me.\n",
      "\n",
      "C-motivation-impact       H-clarity                 ||| The key motivation is to make the pooling operation shift-equivalent and anti-aliasing.\n",
      "\n",
      "E-replicability           H-quantitative-analysis   ||| In contrast, the studied learning rates are asymptotic and there is a big discrepancy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Label\".ljust(25), \"Predicted\".ljust(29), \"Sentence\\n\")\n",
    "for a, b, c in results[:20]:\n",
    "  print(b.ljust(25), c.ljust(25), \"|||\", a)\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
