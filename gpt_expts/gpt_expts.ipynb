{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c690a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Labels ===\n",
      "asp_clarity                 A-clarity\n",
      "asp_meaningful-comparison   B-meaningful-comparison\n",
      "asp_motivation-impact       C-motivation-impact\n",
      "asp_originality             D-originality\n",
      "asp_replicability           E-replicability\n",
      "asp_soundness-correctness   F-soundness-correctness\n",
      "asp_substance               G-substance\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "import disapere_lib\n",
    "\n",
    "def summarize_results(results):\n",
    "  valid_answers = 0\n",
    "  correct_answers = 0\n",
    "\n",
    "  for a, b, c in results:\n",
    "    if c in label_map.values():\n",
    "      valid_answers += 1\n",
    "      if b == c:\n",
    "        correct_answers += 1\n",
    "\n",
    "  valid_percent = valid_answers/len(results)\n",
    "  accuracy = correct_answers/len(results)\n",
    "\n",
    "  print(f\"Valid answers: {valid_percent:.0%}\\nAccuracy: {accuracy:.0%}\")\n",
    "  \n",
    "  print(\"=\" * 80)\n",
    "  \n",
    "  print(\"Label\".ljust(25), \"Predicted\".ljust(29), \"Sentence\\n\")\n",
    "  for a, b, c in results[:20]:\n",
    "    print(b.ljust(25), c.ljust(25), \"|||\", a)\n",
    "    print()\n",
    "\n",
    "    \n",
    "openai.api_key_path = \"nnk_openai_api_key.txt\"\n",
    "MODEL_NAME = \"text-davinci-003\"\n",
    "\n",
    "dataset = disapere_lib.get_dataset('aspect')\n",
    "label_map = {y: f'{x}-{y[4:]}' for x, y in zip(\"ABCDEFG\", sorted(dataset['train'].keys())[1:-1])}\n",
    "\n",
    "old_label_list = sorted(label_map.keys())\n",
    "\n",
    "print(\"=== Labels ===\")\n",
    "for k, v in label_map.items():\n",
    "  print(k.ljust(28) + f'{v}')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dd5c9",
   "metadata": {},
   "source": [
    "# Few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8a2ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  text-davinci-003\n",
      "Number of classes: 7\n",
      "Number of examples per class in prompt: 3\n",
      "Prompt length: 3382\n",
      "\n",
      "Prompt prefix:\n",
      "================================================================================\n",
      "Sentence: Reward prediction along --> Reward prediction alone\n",
      "Label: A-clarity\n",
      "###\n",
      "Sentence: this limitation in latenby?\n",
      "Label: A-clarity\n",
      "###\n",
      "Sentence: In general, the paper is well written and easy to follow. And the experimental evaluation is extensive and compares with relevant state-of-the-art m...\n",
      "================================================================================\n",
      "\n",
      "Number of examples to label: 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_examples_in_prompt = 3\n",
    "num_examples_to_label = 200\n",
    "\n",
    "\n",
    "prompt = \"\"\n",
    "\n",
    "for old_label, new_label in label_map.items():\n",
    "  for _, text in dataset['train'][old_label][:num_examples_in_prompt]:\n",
    "    prompt += f'Sentence: {text}\\nLabel: {new_label}\\n###\\n'\n",
    "    \n",
    "print(\"Model name: \", MODEL_NAME)\n",
    "print(\"Number of classes:\", len(label_map))\n",
    "print(\"Number of examples per class in prompt:\", num_examples_in_prompt)\n",
    "print(\"Prompt length:\", len(prompt))\n",
    "print()\n",
    "\n",
    "print(\"Prompt prefix:\")\n",
    "print(\"=\" * 80)\n",
    "print(prompt[:300]+\"...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\n",
    "print(\"\\nNumber of examples to label:\", num_examples_to_label)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155eac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 200/200 [03:47<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Weird way of picking examples but whatever\n",
    "for i in tqdm.tqdm(range(num_examples_in_prompt, num_examples_in_prompt + num_examples_to_label)):\n",
    "  label = random.choice(old_label_list)\n",
    "  if i >= len(dataset['train'][label]):\n",
    "    continue\n",
    "    \n",
    "  _, sentence = dataset['train'][label][i]\n",
    "  text = f'{prompt}Sentence: {sentence}\\nLabel: '\n",
    "  \n",
    "  response = openai.Completion.create(\n",
    "    engine = MODEL_NAME,\n",
    "    prompt = text,\n",
    "    temperature = 0.6,\n",
    "    max_tokens = 150,\n",
    "  )\n",
    "  \n",
    "  results.append((sentence, label_map[label], response['choices'][0].text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6707768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid answers: 28%\n",
      "Accuracy: 17%\n",
      "================================================================================\n",
      "Label                     Predicted                     Sentence\n",
      "\n",
      "B-meaningful-comparison   B-meaningful-comparison   ||| But there are better baselines possible.\n",
      "\n",
      "E-replicability           E-replicability           ||| The authors should clearly explain how to update \\phi when optimizing Eq 12.\n",
      "\n",
      "C-motivation-impact       A-clarity                 ||| This paper shows some promise when graph network-based controllers augmented with evolutionary algorithms.\n",
      "\n",
      "C-motivation-impact       A-clarity                 ||| The paper clearly states the objective and provides a nice general description of the method.\n",
      "\n",
      "A-clarity                 H-presentation\n",
      "###\n",
      "Sentence: The figures are clear and easy to understand.\n",
      "Label: H-presentation ||| The images are well-presented and well-explained by the captions and the text.\n",
      "\n",
      "E-replicability           H-scope-breadth           ||| The problem of image classification is considered only, while authors claimed the method can be easily applied to other problems as well.\n",
      "\n",
      "C-motivation-impact       H-justification           ||| Considering these improvements, I would like to raise the score to 5, since the setting of combining few-shot learning and domain adaptation is interesting and the proposed model outperforms the baselines.\n",
      "\n",
      "D-originality             H-creativity\n",
      "###\n",
      "Sentence: 2) The paper also proposed a new algorithm for optimizing the upper-bound using an alternating optimization technique.\n",
      "Label: H-creativity ||| 1) The paper proposes a new theoretical upper-bound based on the prior works, the upper-bound and its derivation are interesting and heuristic to the domain adaptation research community.\n",
      "\n",
      "C-motivation-impact       H-overall-evaluation      ||| - I think the work addressed here is important, and though the details are hard to parse and the new contributions seemingly small, it is important enough for practical performance.\n",
      "\n",
      "G-substance               H-theoretical-foundation  ||| 1) The critical issue of this paper is that the algorithm is designed to minimize the upper bound.\n",
      "\n",
      "G-substance               H-adequacy-of-evidence    ||| 2) The experimental results provided in this paper are weak.\n",
      "\n",
      "B-meaningful-comparison   H-presentation            ||| That said, the claims should be weakened to reflect this gap, and domain knowledge should be mentioned more prominently (e.g. states of interest vs context are given, not learned).\n",
      "\n",
      "D-originality             H-overall-assessment      ||| Overall, this paper is good, but is not novel or important enough for acceptance.\n",
      "\n",
      "A-clarity                 H-clarity-presentation    ||| - q_theta was introduced in Eq. (8) before it is defined in Eq. (11).\n",
      "\n",
      "D-originality             H-related-work            ||| Specifically, the policy update in Dreamer resembles that of SVG (Heess et al., 2015), which also backpropagates re-parameterized gradients through a value function and a transition model.\n",
      "\n",
      "E-replicability           H-clarity                 ||| 1. For the evaluation of DBA, I assume that there are 4 adversarial parties, controlling each of the 4 local triggers. When using centralized attacks, are there still 4 adversarial parties, although they share the same global trigger, or if there is only 1 adversarial party?\n",
      "\n",
      "D-originality             D-originality             ||| Since the latent models are learned based on existing techniques, the paper presents an incremental contribution.\n",
      "\n",
      "D-originality             D-originality             ||| Though, I still think the contribution is incremental, since back-propagating gradients through values and dynamics has been studied in prior works (albeit with less empirical successes compared to Dreamer).\n",
      "\n",
      "A-clarity                 A-clarity                 ||| - The paper is well written and easy to read.\n",
      "\n",
      "D-originality             D-originality             ||| - To my best knowledge, the idea of applying the meta-learning to the automatic generation of auxiliary tasks is novel.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075b8bf",
   "metadata": {},
   "source": [
    "# Zero shot\n",
    "\n",
    "Following guidelines from [Ziems et al. 2023](https://arxiv.org/abs/2305.03514) (for Latent Hatred, which is most similar to DISAPERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5bc029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_suffix = \"\"\"\\n\\nWhich of the following aspects does the sentence above mention?\n",
    "A-clarity: Is the paper clear, well-written and well-structured?\n",
    "B-meaningful-comparison: Are the comparisons to prior work sufficient and fair?\n",
    "C-motivation-impact: Does the paper address an important problem?\n",
    "D-originality: Are there new topics, technique, methodology, or insights?\n",
    "E-replicability: Is it easy to reproduce and verify the correctness of the results?\n",
    "F-soundness-correctness: Is the approach sound? Are the claims supported?\n",
    "G-substance: Are there substantial experiments and/or detailed analyses?\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a23a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████▏         | 151/200 [04:50<01:27,  1.79s/it]"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Weird way of picking examples but whatever\n",
    "for i in tqdm.tqdm(range(num_examples_to_label)):\n",
    "  label = random.choice(old_label_list)\n",
    "  if i >= len(dataset['train'][label]):\n",
    "    continue\n",
    "    \n",
    "  _, sentence = dataset['train'][label][i]\n",
    "  text = f'{sentence}{prompt_suffix}'\n",
    "  \n",
    "  response = openai.Completion.create(\n",
    "    engine = MODEL_NAME,\n",
    "    prompt = text,\n",
    "    temperature = 0.6,\n",
    "    max_tokens = 150,\n",
    "  )\n",
    "  \n",
    "  results.append((sentence, label_map[label].strip(), response['choices'][0].text.strip().split(\":\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
